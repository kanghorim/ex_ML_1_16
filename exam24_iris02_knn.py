# -*- coding: utf-8 -*-
"""exam24_iris02_knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FdX_DQIyhn1pxJnznAMLF18Olvs2cpX7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

plt.rcParams['figure.figsize'] = [7, 7]
sns.set(style='darkgrid')
plt.rcParams['scatter.edgecolors'] = 'black'
pd.set_option('display.max_columns', None)
pd.set_option('display.max_row', None)
pd.set_option('display.unicode.east_asian_width', True)

iris_dataset = load_iris()
iris = pd.DataFrame(iris_dataset.data,
        columns=iris_dataset.feature_names)
labels = iris_dataset.target_names
iris.info()
print(iris.head())

labels

label = iris_dataset.target
print(label)

scaler = StandardScaler()
iris = scaler.fit_transform(iris)
Features = pd.DataFrame(iris, columns=['SL', 'SW', 'PL', 'PW'])
print(Features.shape)

X_train, X_test, Y_train, Y_test = train_test_split(
    Features, label, test_size=0.2)
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier

accuracy_rate = []
error_rate = []
for i in range(1, 50):
  knn = KNeighborsClassifier(n_neighbors=i)
  score = cross_val_score(knn, Features, label, cv = 17)
  accuracy_rate.append(score.mean())
  error_rate.append(1-score.mean())

plt.figure(figsize=(10, 6))
plt.plot(range(1, 50), accuracy_rate, color='b',
         linestyle='dashed', marker='o',
         markerfacecolor='r', markersize=10)
plt.title('Accuracy Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Accuracy Rate')
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(range(1, 50), error_rate, color='b',
         linestyle='dashed', marker='o',
         markerfacecolor='r', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')
plt.show()

model_predict_error_rate = []
for i in range(1,50):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(X_train, Y_train)
  pred_i = knn.predict(X_test)
  model_predict_error_rate.append(np.mean(pred_i != Y_test)) # 에러율 확인코드

plt.figure(figsize = (10,10))
plt.plot(range(1,50), model_predict_error_rate,
         linestyle = 'dashed', marker = 'o',
         color = 'b', markersize = 10)
plt.title('Model predict error rate vs.K value')
plt.xlabel('K')
plt.ylabel('Model predict error rate')
plt.show()

for i in range(1, 1000):
    X_train, X_test, Y_train, Y_test = train_test_split(
        Features, label, test_size=0.2, random_state=i)
    IrisKNN = KNeighborsClassifier(n_neighbors=6)
    IrisKNN.fit(X_train, Y_train)
    train_score = IrisKNN.score(X_train, Y_train)
    test_score = IrisKNN.score(X_test, Y_test)
    if test_score > train_score: # 과적합 안난것만 하겠다
        print('Test: {} Train: {} RandomState: {}'.format(
            test_score, train_score, i))

X_train, X_test, Y_train, Y_test = train_test_split(
      Features, label, test_size=0.2, random_state=960)
IrisKNN = KNeighborsClassifier(n_neighbors=6)
IrisKNN.fit(X_train, Y_train)
train_score = IrisKNN.score(X_train, Y_train)
print(train_score)
test_score = IrisKNN.score(X_test, Y_test)
print(test_score)

from sklearn.metrics import classification_report, confusion_matrix
pd.DataFrame(confusion_matrix(Y_test, IrisKNN.predict(X_test)),
                              columns = ['P_setosa','P_versicolor','P_virginica'],
                              index = ['A_setosa','A_versicolor','A_virginica'])

print(classification_report(Y_test, IrisKNN.predict(X_test))) # 데이터 불균형이 나왔음

print(classification_report(Y_train, IrisKNN.predict(X_train)))

from sklearn.model_selection import StratifiedShuffleSplit # 그룹별로 랜덤하게 나눈거
cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2)

accuracies = cross_val_score(IrisKNN, Features, label,
                             cv=cv, scoring='accuracy')
print('Cross-Validation accuracy scores:{}'.format(accuracies))
print('Mean Cross-Validation accuracy score: {}'.format(round(accuracies.mean(), 3)))

from sklearn.model_selection import GridSearchCV

k_range = range(1, 50)
weights_options=['uniform', 'distance']
param = {'n_neighbors':k_range, 'weights':weights_options}
cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2)
IrisKNN = GridSearchCV(KNeighborsClassifier(), 
            param, cv=cv, verbose=False, n_jobs=-1)
IrisKNN.fit(X_train, Y_train)

print(IrisKNN.best_score_)
print(IrisKNN.best_params_)
print(IrisKNN.best_estimator_)

IrisKNN = IrisKNN.best_estimator_
print(IrisKNN.score(X_test, Y_test))

pd.DataFrame(confusion_matrix(Y_test, IrisKNN.predict(X_test)),
                              columns = ['P_setosa','P_versicolor','P_virginica'],
                              index = ['A_setosa','A_versicolor','A_virginica'])

print(classification_report(Y_test, IrisKNN.predict(X_test))) # 데이터 불균형이 나왔음

