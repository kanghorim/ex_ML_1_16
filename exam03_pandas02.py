# -*- coding: utf-8 -*-
"""exam03_pandas02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Sia-eaNqakSLmvWp-F_qkUpMCu_P9qm
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import preprocessing

pd.set_option('display.max_columns', 8)
pd.set_option('display.unicode.east_asian', True)

df = sns.load_dataset('titanic')
print(df.head(20))

nan_deck = df['deck'].value_counts(dropna=False)
print(nan_deck)
print(type(nan_deck))

print(df.head().isnull())

print(df.head().notnull())

print(df.isnull().sum(axis=0))

df.info()

df.dropna(axis=1, thresh=500, inplace=True)
print(df.columns)

df_age = df.dropna(subset=['age'], how='any', axis=0)
df_age.info()

mean_age = df['age'].mean()
df['age'].fillna(mean_age, inplace=True)
print(df.head(10))

most_freq = df['embark_town'].value_counts(dropna=True).idxmax()
print(most_freq)

df_most_freq = df['embark_town'].fillna(most_freq, inplace=False)
print(df_most_freq[825:830])
print(df[825:830])

df['embark_town'].fillna(method='ffill', inplace=True)
print(df['embark_town'][825:831])

df.drop(['survived', 'embarked'],axis=1, inplace=True)
df.info()

print(df.isnull().sum(axis=0))

df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],
                   'c2':[1, 1, 1, 2, 2],
                   'c3':[1, 1, 2, 2, 2]})
print(df)

df_dup = df.duplicated()
print(df_dup)

df_dup = df['c2'].duplicated()
print(df_dup)

df2 = df.drop_duplicates()
print(df2)

df2 = df.drop_duplicates(subset=['c2', 'c3'])
print(df2)

df = pd.read_csv('./datasets/auto-mpg.csv', header=None)
df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower',
           'weight', 'acceleration', 'model year',
           'origin', 'name']
print(df.head())

mpg_to_kpl = 0.425144
df['kpl'] = df['mpg'] * mpg_to_kpl
print(df.head(20))

df['kpl'] = df['kpl'].round(2)
print(df.head())

df.info()

print(df['horsepower'].unique())

df['horsepower'].replace('?', np.nan, inplace=True)
df.dropna(subset=['horsepower'], axis=0, inplace=True)
df['horsepower'] = df['horsepower'].astype('float')
df.info()

print(df['horsepower'].unique())

print(df['origin'].unique())

df['origin'].replace({1:'USA', 2:'EU', 3:'JP'}, inplace=True)
print(df['origin'].unique())
print(df['origin'])
print(df['origin'].value_counts())

print(df['origin'].dtypes)

df['origin'] = df['origin'].astype('category')
print(df['origin'].dtypes)
print(df['origin'])

df['origin'] = df['origin'].astype('str')
print(df['origin'].dtypes)
print(df['origin'])

count, bin_dividers = np.histogram(df['horsepower'], bins=3)
print(count)
print(bin_dividers)

bin_names = ['저출력', '보통출력', '고출력']
df['hp_bin'] = pd.cut(x=df['horsepower'], bins=bin_dividers,
                      labels=bin_names, include_lowest=True)
print(df[['horsepower', 'hp_bin']].head(20))

df.info()

label_encoder = preprocessing.LabelEncoder()
onehot_encoder = preprocessing.OneHotEncoder()

hp_bin_labeled = \
    label_encoder.fit_transform(df['hp_bin'].head(15))
print(hp_bin_labeled)
print(type(hp_bin_labeled))
print(label_encoder.classes_)

print(hp_bin_labeled.shape)

hp_bin_labeled = hp_bin_labeled.reshape(-1, 1)
print(hp_bin_labeled)
print(hp_bin_labeled.shape)

onehot_pitted = onehot_encoder.fit_transform(hp_bin_labeled)
print(onehot_pitted)

df1 = df[['horsepower', 'hp_bin']]
df2 = pd.get_dummies(df1)
df2

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import MinMaxScaler

data = np.array([4, 5, 6, 7, 8])
min = 4
max = 8

data1 = data -4
print(data1)

data1 = data1 / 4
print(data1)

data2 = (data - min) / (max - min)
print(data2)

minmaxscaler = MinMaxScaler()
data3 = minmaxscaler.fit_transform(data.reshape(-1, 1))
print(data3)

